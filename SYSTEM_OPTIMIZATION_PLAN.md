# üöÄ –ü–õ–ê–ù –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –°–ò–°–¢–ï–ú–´ VHM24R

## üìä –ê–ù–ê–õ–ò–ó –¢–ï–ö–£–©–ï–ì–û –°–û–°–¢–û–Ø–ù–ò–Ø

### ‚úÖ –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´
- 12 —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
- –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π Vue.js 3 frontend
- Telegram Bot —Å –≤–∏–∑—É–∞–ª—å–Ω—ã–º–∏ –º–µ–Ω—é
- Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è
- –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´
1. **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ë–î**: N+1 –∑–∞–ø—Ä–æ—Å—ã, —á–∞—Å—Ç—ã–µ –∫–æ–º–º–∏—Ç—ã
2. **–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤**: –ß–∞—Å—Ç—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –ë–î –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ
3. **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ—Å—Ç–æ–≤**: –ù–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
4. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥**: –ë–∞–∑–æ–≤–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑ –º–µ—Ç—Ä–∏–∫

## üéØ –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ï –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò

### 1. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–• (–ö–†–ò–¢–ò–ß–ù–û)

#### –ü—Ä–æ–±–ª–µ–º–∞: N+1 –∑–∞–ø—Ä–æ—Å—ã –≤ CRUD –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
```python
# ‚ùå –¢–µ–∫—É—â–∏–π –∫–æ–¥ –≤ crud.py
def approve_user(db: Session, user_id: int, approved_by: int):
    user = db.query(User).filter(User.id == user_id).first()
    if user:
        setattr(user, 'status', 'approved')
        db.commit()  # –ö–æ–º–º–∏—Ç –Ω–∞ –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
```

#### ‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
```python
def approve_users_batch(db: Session, user_ids: List[int], approved_by: int):
    """–ë–∞—Ç—á–µ–≤–æ–µ –æ–¥–æ–±—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    db.query(User).filter(User.id.in_(user_ids)).update(
        {"status": "approved", "approved_by": approved_by, "approved_at": datetime.utcnow()},
        synchronize_session=False
    )
    db.commit()
    return db.query(User).filter(User.id.in_(user_ids)).all()

def get_orders_with_relations(db: Session, page: int = 1, page_size: int = 50):
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å eager loading"""
    return db.query(Order).options(
        joinedload(Order.user),
        joinedload(Order.file),
        joinedload(Order.changes)
    ).offset((page - 1) * page_size).limit(page_size).all()
```

#### –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```sql
-- –î–æ–±–∞–≤–∏—Ç—å –≤ –º–∏–≥—Ä–∞—Ü–∏—é Alembic
CREATE INDEX CONCURRENTLY idx_orders_creation_time ON orders(creation_time);
CREATE INDEX CONCURRENTLY idx_orders_machine_code ON orders(machine_code);
CREATE INDEX CONCURRENTLY idx_orders_status_time ON orders(match_status, creation_time);
CREATE INDEX CONCURRENTLY idx_user_telegram_status ON users(telegram_id, status);
CREATE INDEX CONCURRENTLY idx_order_changes_order_time ON order_changes(order_id, change_time);

-- –ö–æ–º–ø–æ–∑–∏—Ç–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
CREATE INDEX CONCURRENTLY idx_orders_complex ON orders(match_status, creation_time, machine_code);
```

### 2. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò –§–ê–ô–õ–û–í (–í–´–°–û–ö–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢)

#### –ü—Ä–æ–±–ª–µ–º–∞: –ß–∞—Å—Ç—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –ë–î
```python
# ‚ùå –¢–µ–∫—É—â–∏–π –∫–æ–¥ –≤ file_processor.py
for idx, (row_idx, row) in enumerate(df.iterrows()):
    if idx % 100 == 0:
        progress = (idx / total_rows) * 100
        crud.update_order(db, order_id, {"progress_percentage": progress})
```

#### ‚úÖ –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
```python
class OptimizedFileProcessor:
    BATCH_SIZE = 1000
    PROGRESS_UPDATE_INTERVAL = 5000
    
    async def process_file_optimized(self, file_path: str, order_id: int, user_id: int):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ —Å –±–∞—Ç—á–∏–Ω–≥–æ–º"""
        df = await self.load_file_async(file_path)
        total_rows = len(df)
        
        changes_batch = []
        processed_count = 0
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞–º–∏
        for idx, (row_idx, row) in enumerate(df.iterrows()):
            change_data = self.prepare_change_data(row, order_id, user_id)
            changes_batch.append(change_data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞—Ç—á –≤ –ë–î
            if len(changes_batch) >= self.BATCH_SIZE:
                await self.save_changes_batch(changes_batch)
                processed_count += len(changes_batch)
                changes_batch = []
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å —Ä–µ–∂–µ
                if idx % self.PROGRESS_UPDATE_INTERVAL == 0:
                    await self.update_progress(order_id, processed_count, total_rows)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ
        if changes_batch:
            await self.save_changes_batch(changes_batch)
            processed_count += len(changes_batch)
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        await self.update_progress(order_id, processed_count, total_rows, completed=True)
        
        return {
            "total_rows": total_rows,
            "processed_rows": processed_count,
            "processing_time": time.time() - start_time
        }
    
    async def save_changes_batch(self, changes_batch: List[dict]):
        """–ë–∞—Ç—á–µ–≤–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        async with self.db_session() as db:
            db.bulk_insert_mappings(OrderChange, changes_batch)
            await db.commit()
    
    async def load_file_async(self, file_path: str) -> pd.DataFrame:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞"""
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor(max_workers=2) as executor:
            return await loop.run_in_executor(executor, pd.read_csv, file_path)
```

### 3. –°–ò–°–¢–ï–ú–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø (–í–´–°–û–ö–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢)

#### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ—Å—Ç–æ–≤
```python
# backend/tests/conftest.py
import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.main import app
from app.database import get_db, Base

SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

@pytest.fixture(scope="session")
def db():
    Base.metadata.create_all(bind=engine)
    db = TestingSessionLocal()
    try:
        yield db
    finally:
        db.close()
        Base.metadata.drop_all(bind=engine)

@pytest.fixture
def client(db):
    def override_get_db():
        try:
            yield db
        finally:
            db.close()
    
    app.dependency_overrides[get_db] = override_get_db
    yield TestClient(app)
    app.dependency_overrides.clear()

# backend/tests/test_file_processor.py
import pytest
from unittest.mock import Mock, patch, AsyncMock
from app.services.file_processor import OptimizedFileProcessor

class TestFileProcessor:
    @pytest.fixture
    def processor(self):
        return OptimizedFileProcessor()
    
    @pytest.mark.asyncio
    async def test_csv_processing_performance(self, processor):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ CSV"""
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π CSV —Ñ–∞–π–ª
        test_data = self.create_test_csv(1000)  # 1000 —Å—Ç—Ä–æ–∫
        
        start_time = time.time()
        result = await processor.process_file_optimized(test_data, 1, 1)
        processing_time = time.time() - start_time
        
        assert result["processed_rows"] == 1000
        assert processing_time < 5.0  # –î–æ–ª–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –∑–∞ < 5 —Å–µ–∫—É–Ω–¥
    
    @pytest.mark.asyncio
    async def test_batch_processing(self, processor):
        """–¢–µ—Å—Ç –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        with patch.object(processor, 'save_changes_batch', new_callable=AsyncMock) as mock_save:
            test_data = self.create_test_csv(2500)  # 2.5 –±–∞—Ç—á–∞
            
            await processor.process_file_optimized(test_data, 1, 1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ save_changes_batch –≤—ã–∑—ã–≤–∞–ª—Å—è 3 —Ä–∞–∑–∞ (2 –ø–æ–ª–Ω—ã—Ö –±–∞—Ç—á–∞ + –æ—Å—Ç–∞—Ç–æ–∫)
            assert mock_save.call_count == 3

# backend/tests/test_api_performance.py
import pytest
import time
from fastapi.testclient import TestClient

class TestAPIPerformance:
    def test_orders_endpoint_performance(self, client):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ –∑–∞–∫–∞–∑–æ–≤"""
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.create_test_orders(100)
        
        start_time = time.time()
        response = client.get("/api/v1/orders?page=1&page_size=50")
        response_time = time.time() - start_time
        
        assert response.status_code == 200
        assert response_time < 0.2  # < 200ms
        assert len(response.json()["orders"]) <= 50
    
    def test_concurrent_requests(self, client):
        """–¢–µ—Å—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        import concurrent.futures
        
        def make_request():
            return client.get("/api/v1/orders")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(make_request) for _ in range(20)]
            results = [f.result() for f in futures]
        
        # –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É—Å–ø–µ—à–Ω—ã–º–∏
        assert all(r.status_code == 200 for r in results)
```

### 4. –ú–û–ù–ò–¢–û–†–ò–ù–ì –ò –ú–ï–¢–†–ò–ö–ò (–°–†–ï–î–ù–ò–ô –ü–†–ò–û–†–ò–¢–ï–¢)

#### Prometheus –º–µ—Ç—Ä–∏–∫–∏
```python
# backend/app/monitoring.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from fastapi import Request, Response
import time

# –ú–µ—Ç—Ä–∏–∫–∏
REQUEST_COUNT = Counter(
    'vhm24r_requests_total', 
    'Total HTTP requests', 
    ['method', 'endpoint', 'status_code']
)

REQUEST_DURATION = Histogram(
    'vhm24r_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint']
)

FILE_PROCESSING_DURATION = Histogram(
    'vhm24r_file_processing_seconds',
    'File processing duration in seconds',
    ['file_type']
)

ACTIVE_USERS = Gauge(
    'vhm24r_active_users',
    'Number of active users'
)

DATABASE_CONNECTIONS = Gauge(
    'vhm24r_db_connections',
    'Number of database connections'
)

@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    """Middleware –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫"""
    start_time = time.time()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º endpoint
    endpoint = request.url.path
    method = request.method
    
    try:
        response = await call_next(request)
        status_code = response.status_code
    except Exception as e:
        status_code = 500
        raise
    finally:
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        duration = time.time() - start_time
        REQUEST_COUNT.labels(method=method, endpoint=endpoint, status_code=status_code).inc()
        REQUEST_DURATION.labels(method=method, endpoint=endpoint).observe(duration)
    
    return response

@app.get("/metrics")
async def get_metrics():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è Prometheus"""
    return Response(generate_latest(), media_type="text/plain")

# –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∏
class BusinessMetrics:
    @staticmethod
    def record_file_processing(file_type: str, duration: float):
        FILE_PROCESSING_DURATION.labels(file_type=file_type).observe(duration)
    
    @staticmethod
    def update_active_users(count: int):
        ACTIVE_USERS.set(count)
    
    @staticmethod
    def update_db_connections(count: int):
        DATABASE_CONNECTIONS.set(count)
```

#### –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
# backend/app/logging_config.py
import structlog
import logging
from datetime import datetime

def configure_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ
logger = structlog.get_logger()

async def process_file_with_logging(file_path: str, order_id: int):
    logger.info(
        "file_processing_started",
        file_path=file_path,
        order_id=order_id,
        user_id=user_id
    )
    
    try:
        result = await process_file(file_path, order_id)
        logger.info(
            "file_processing_completed",
            order_id=order_id,
            processed_rows=result["processed_rows"],
            duration=result["processing_time"]
        )
        return result
    except Exception as e:
        logger.error(
            "file_processing_failed",
            order_id=order_id,
            error=str(e),
            exc_info=True
        )
        raise
```

### 5. –£–õ–£–ß–®–ï–ù–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–û–ö

```python
# backend/app/exceptions.py
from enum import Enum
from fastapi import HTTPException, Request
from fastapi.responses import JSONResponse

class ErrorCode(Enum):
    # –§–∞–π–ª–æ–≤—ã–µ –æ—à–∏–±–∫–∏
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    INVALID_FILE_FORMAT = "INVALID_FILE_FORMAT"
    FILE_PROCESSING_FAILED = "FILE_PROCESSING_FAILED"
    
    # –û—à–∏–±–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    INVALID_CREDENTIALS = "INVALID_CREDENTIALS"
    TOKEN_EXPIRED = "TOKEN_EXPIRED"
    INSUFFICIENT_PERMISSIONS = "INSUFFICIENT_PERMISSIONS"
    
    # –û—à–∏–±–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    RECORD_NOT_FOUND = "RECORD_NOT_FOUND"
    DUPLICATE_RECORD = "DUPLICATE_RECORD"
    DATABASE_ERROR = "DATABASE_ERROR"

class VHMError(Exception):
    def __init__(self, code: ErrorCode, message: str, details: dict = None, status_code: int = 400):
        self.code = code
        self.message = message
        self.details = details or {}
        self.status_code = status_code

@app.exception_handler(VHMError)
async def vhm_error_handler(request: Request, exc: VHMError):
    logger.error(
        "application_error",
        error_code=exc.code.value,
        message=exc.message,
        details=exc.details,
        path=request.url.path
    )
    
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": {
                "code": exc.code.value,
                "message": exc.message,
                "details": exc.details,
                "timestamp": datetime.utcnow().isoformat()
            }
        }
    )

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ
async def upload_file(file: UploadFile):
    if file.size > MAX_FILE_SIZE:
        raise VHMError(
            ErrorCode.FILE_TOO_LARGE,
            f"File size {file.size} exceeds maximum allowed size {MAX_FILE_SIZE}",
            {"max_size": MAX_FILE_SIZE, "actual_size": file.size}
        )
```

## üìà –ü–õ–ê–ù –í–ù–ï–î–†–ï–ù–ò–Ø

### –§–∞–∑–∞ 1: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è (1-2 –Ω–µ–¥–µ–ª–∏)
1. ‚úÖ –ò—Å–ø—Ä–∞–≤–∏—Ç—å N+1 –∑–∞–ø—Ä–æ—Å—ã –≤ CRUD –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
2. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
3. ‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–æ–≤ —Å –±–∞—Ç—á–∏–Ω–≥–æ–º
4. ‚úÖ –í–Ω–µ–¥—Ä–∏—Ç—å –±–∞–∑–æ–≤–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –§–∞–∑–∞ 2: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (1 –Ω–µ–¥–µ–ª—è)
1. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å Prometheus –º–µ—Ç—Ä–∏–∫–∏
2. ‚úÖ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
3. ‚úÖ –£–ª—É—á—à–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
4. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å health checks

### –§–∞–∑–∞ 3: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è (1-2 –Ω–µ–¥–µ–ª–∏)
1. ‚úÖ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
2. ‚úÖ –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—è–∂–µ–ª—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
3. ‚úÖ Progressive Web App —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
4. ‚úÖ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

## üéØ –û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- **–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤**: —Å 1000 —Å—Ç—Ä–æ–∫/—Å–µ–∫ –¥–æ 5000+ —Å—Ç—Ä–æ–∫/—Å–µ–∫
- **API Response Time**: —Å 200ms –¥–æ <100ms –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- **Memory Usage**: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–∞ 30-40%

### –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å
- **Test Coverage**: 0% ‚Üí 80%+
- **Error Handling**: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫
- **Monitoring**: –ü–æ–ª–Ω–∞—è –≤–∏–¥–∏–º–æ—Å—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã

### –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å
- **Concurrent Users**: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ 100+ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- **File Processing**: –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
- **Database**: –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤ –¥–∞–Ω–Ω—ã—Ö

## üîß –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ –î–õ–Ø –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê

```yaml
# docker-compose.monitoring.yml
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-storage:/var/lib/grafana
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data

volumes:
  grafana-storage:
  redis-data:
```

–≠—Ç–æ—Ç –ø–ª–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç VHM24R –≤ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—É—é, –Ω–∞–¥–µ–∂–Ω—É—é –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º—É—é —Å–∏—Å—Ç–µ–º—É! üöÄ
